{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "import struct\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import linear_model\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(path):\n",
    "    return pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_raw = load_csv(\"data/train_V2_copia.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_raw.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to format the three first attributes because of theses strings can't be used to fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_format = training_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_format[\"Id\"] = np.arange(len(training_format))\n",
    "training_format[\"groupId\"] = np.arange(len(training_format))\n",
    "training_format[\"matchId\"] = np.arange(len(training_format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_raw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "training_raw.hist(bins=50, figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_format[\"killPlaceAVG\"] = training_format[\"killPlace\"].mean()\n",
    "#training_format[\"overallKills\"] = \n",
    "#training_format[\"overallDBNOS\"] = \n",
    "#training_format[\"overallMatches\"] = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(training_format, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f'Training data: {train_set.shape}\\nTest data: {test_set.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discover and visualize the data to gain insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking for Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_copy = train_set.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = training_copy.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "corr_matrix[\"winPlacePerc\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Attributes that seem more correlated with \"winPlacePerc\" are:\n",
    "walkDistance   \n",
    "killPlace\n",
    "boosts             \n",
    "weaponsAcquired    \n",
    "damageDealt        \n",
    "heals              \n",
    "kills \n",
    "longestKill       \n",
    "killStreaks       \n",
    "rideDistance     \n",
    "assists           \n",
    "DBNOs           \n",
    "headshotKills   \n",
    "revives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attributes = [\"winPlacePerc\", \"walkDistance\", \"killPlace\",\n",
    "#\"boosts\"]\n",
    "\n",
    "#scatter_matrix(training_copy[attributes], figsize=(12, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#training_copy.plot(kind=\"scatter\", x=\"walkDistance\", y=\"winPlacePerc\",alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_copy.plot(kind=\"scatter\", x=\"matchDuration\", y=\"winPlacePerc\",alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data for Machine Learning algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLabelBinarizer(TransformerMixin):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.encoder = LabelBinarizer(*args, **kwargs)\n",
    "    def fit(self, x, y=0):\n",
    "        self.encoder.fit(x)\n",
    "        return self\n",
    "    def transform(self, x, y=0):\n",
    "        return self.encoder.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_set.drop(\"winPlacePerc\", axis=1)\n",
    "train_labels = train_set[\"winPlacePerc\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test_set.drop(\"winPlacePerc\", axis=1)\n",
    "test_labels = test_set[\"winPlacePerc\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = train_set.drop(\"winPlacePerc\", axis=1)\n",
    "test_set = test_set.drop(\"winPlacePerc\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attribs = list(train_set.drop(\"matchType\", axis=1))\n",
    "cat_attribs = [\"matchType\"]\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(num_attribs)),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "cat_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(cat_attribs)),\n",
    "        ('label_binarizer', MyLabelBinarizer()),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "        (\"num_pipeline\", num_pipeline),\n",
    "        (\"cat_pipeline\", cat_pipeline),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUBG_TRAIN = full_pipeline.fit_transform(train)\n",
    "PUBG_TEST = full_pipeline.fit_transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select a model and train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(PUBG_TRAIN, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUBG_predictions = lin_reg.predict(PUBG_TEST)\n",
    "lin_mse = mean_squared_error(test_labels, PUBG_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lin_scores = cross_val_score(lin_reg, PUBG_TEST, test_labels,\n",
    "scoring=\"neg_mean_squared_error\", cv=10)\n",
    "lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "display_scores(lin_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg.fit(PUBG_TRAIN, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUBG_predictions = tree_reg.predict(PUBG_TEST)\n",
    "tree_mse = mean_squared_error(test_labels, PUBG_predictions)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "tree_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tree_scores = cross_val_score(tree_reg, PUBG_TEST, test_labels,\n",
    "scoring=\"neg_mean_squared_error\", cv=10)\n",
    "tree_rmse_scores = np.sqrt(-tree_scores)\n",
    "display_scores(tree_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With GridSearchCV this is the best estimator for RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_reg =RandomForestRegressor(bootstrap=True, max_features=8, n_estimators=30)\n",
    "forest_reg.fit(PUBG_TRAIN, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUBG_predictions = forest_reg.predict(PUBG_TEST)\n",
    "forest_mse = mean_squared_error(test_labels, PUBG_predictions)\n",
    "forest_rmse = np.sqrt(forest_mse)\n",
    "forest_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_scores = cross_val_score(forest_reg, PUBG_TEST, test_labels,\n",
    "scoring=\"neg_mean_squared_error\", cv=10)\n",
    "forest_rmse_scores = np.sqrt(-forest_scores)\n",
    "display_scores(forest_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying extra models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HuberRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = linear_model.HuberRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.fit(PUBG_TRAIN, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUBG_predictions = reg.predict(PUBG_TEST)\n",
    "reg_mse = mean_squared_error(test_labels, PUBG_predictions)\n",
    "reg_rmse = np.sqrt(reg_mse)\n",
    "reg_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reg_scores = cross_val_score(reg, PUBG_TEST, test_labels,\n",
    "scoring=\"neg_mean_squared_error\", cv=10)\n",
    "reg_scores = np.sqrt(-reg_scores)\n",
    "display_scores(reg_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg2 = linear_model.SGDRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg2.fit(PUBG_TRAIN, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUBG_predictions = reg2.predict(PUBG_TEST)\n",
    "reg2_mse = mean_squared_error(test_labels, PUBG_predictions)\n",
    "reg2_rmse = np.sqrt(reg2_mse)\n",
    "reg2_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reg2_scores = cross_val_score(reg2, PUBG_TEST, test_labels,\n",
    "scoring=\"neg_mean_squared_error\", cv=10)\n",
    "reg2_scores = np.sqrt(-reg2_scores)\n",
    "display_scores(reg2_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "reg3 = MLPRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg3.fit(PUBG_TRAIN, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUBG_predictions = reg3.predict(PUBG_TEST)\n",
    "reg3_mse = mean_squared_error(test_labels, PUBG_predictions)\n",
    "reg3_rmse = np.sqrt(reg3_mse)\n",
    "reg3_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reg3_scores = cross_val_score(reg3, PUBG_TEST, test_labels,\n",
    "scoring=\"neg_mean_squared_error\", cv=10)\n",
    "reg3_scores = np.sqrt(-reg3_scores)\n",
    "display_scores(reg3_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE and RMSE of all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "benchmark_dict = {'MSE':[lin_mse,\n",
    "                                     tree_mse,\n",
    "                                     forest_mse,\n",
    "                                     reg_mse,\n",
    "                                     reg2_mse,\n",
    "                                     reg3_mse],\n",
    "                  'RMSE':[lin_rmse,\n",
    "                                     tree_rmse,\n",
    "                                     forest_rmse,\n",
    "                                     reg_rmse,\n",
    "                                     reg2_rmse,\n",
    "                                     reg3_rmse]\n",
    "                 }\n",
    "benchmark_data_frame = pd.DataFrame(data=benchmark_dict,\n",
    "                                    index =['Linear Regression',\n",
    "                                            'Decision Tree Regressor',\n",
    "                                            'Random Forest Regressor',\n",
    "                                            'Huber Regressor',\n",
    "                                            'SGD Regressor',\n",
    "                                            'MLP Regressor']\n",
    "                                    )\n",
    "benchmark_data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation scores of all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_dict = {'Mean':[lin_scores.mean(),\n",
    "                                     tree_scores.mean(),\n",
    "                                     forest_scores.mean(),\n",
    "                                     reg_scores.mean(),\n",
    "                                     reg2_scores.mean(),\n",
    "                                     reg3_scores.mean()],\n",
    "                  'Standard deviation':[lin_scores.std(),\n",
    "                                     tree_scores.std(),\n",
    "                                     forest_scores.std(),\n",
    "                                     reg_scores.std(),\n",
    "                                     reg2_scores.std(),\n",
    "                                     reg3_scores.std()]\n",
    "                 }\n",
    "benchmark_data_frame = pd.DataFrame(data=benchmark_dict,\n",
    "                                    index =['Linear Regression',\n",
    "                                            'Decision Tree Regressor',\n",
    "                                            'Random Forest Regressor',\n",
    "                                            'Huber Regressor',\n",
    "                                            'SGD Regressor',\n",
    "                                            'MLP Regressor']\n",
    "                                    )\n",
    "benchmark_data_frame"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
